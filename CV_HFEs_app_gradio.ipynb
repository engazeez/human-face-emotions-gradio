{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "img_size = 128\n",
        "class_names = [\"Angry\", \"Fear\", \"Happy\", \"Sad\", \"Suprise\"]  # sorted folder names"
      ],
      "metadata": {
        "id": "a12mc-AZFqHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "Vruqt9wYFXCv",
        "outputId": "1ccee4a4-1ed0-4fcb-a5cf-4bb8f80f9317"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://09f3e23f1337650dfb.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://09f3e23f1337650dfb.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# app_gradio.py\n",
        "from typing import List\n",
        "import sys\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# --------------------------- Gradio (with consent, blur-preview) ---------------------------\n",
        "def launch_gradio(model: keras.Model, class_names: List[str], img_size: int) -> None:\n",
        "    try:\n",
        "        import gradio as gr\n",
        "    except Exception:\n",
        "        sys.stderr.write(\"Gradio not installed. Try: pip install gradio\\n\")\n",
        "        return\n",
        "\n",
        "    # Optional CV dependency (faster blur/resize). Falls back to PIL if missing.\n",
        "    try:\n",
        "        import cv2  # type: ignore\n",
        "    except Exception:\n",
        "        cv2 = None\n",
        "\n",
        "    import numpy as np\n",
        "    from PIL import Image, ImageFilter\n",
        "\n",
        "    PRIVACY_TEXT = \"\"\"\n",
        "### Privacy & Consent\n",
        "By proceeding, you confirm you have the right to upload this image and consent to its processing **in this session** for emotion classification.\n",
        "- Images are processed in-session; no retention beyond this session.\n",
        "- Do not upload sensitive/identifiable images without permission.\n",
        "\"\"\"\n",
        "\n",
        "    def _resize_np(img_np, size: int):\n",
        "        if cv2 is not None:\n",
        "            return cv2.resize(img_np, (size, size), interpolation=cv2.INTER_AREA)\n",
        "        return np.array(Image.fromarray(img_np).resize((size, size)))\n",
        "\n",
        "    def _maybe_blur_preview(pil_img: Image.Image, blur: bool) -> Image.Image:\n",
        "        # UI preview anonymization only; model runs on original unless you change logic below\n",
        "        return pil_img.filter(ImageFilter.GaussianBlur(radius=12)) if blur else pil_img\n",
        "\n",
        "    def _predict_core(pil_img: Image.Image):\n",
        "        img_np = np.array(pil_img.convert(\"RGB\"))\n",
        "        img_np = _resize_np(img_np, img_size)\n",
        "        x = (img_np.astype(np.float32) / 255.0)[None, ...]\n",
        "        probs = model.predict(x, verbose=0)[0]\n",
        "        pred_id = int(np.argmax(probs))\n",
        "        pred_label = class_names[pred_id]\n",
        "        probs_dict = {class_names[i]: float(probs[i]) for i in range(len(class_names))}\n",
        "        return probs_dict, pred_label\n",
        "\n",
        "    def toggle_uploader(consent: bool):\n",
        "        if not consent:\n",
        "            # Hide and reset everything when consent revoked\n",
        "            return (\n",
        "                gr.update(visible=False, value=None),  # file\n",
        "                gr.update(value=None),                 # preview\n",
        "                gr.update(value={}),                   # probs\n",
        "                gr.update(value=\"\"),                   # label\n",
        "            )\n",
        "        return (gr.update(visible=True), gr.update(), gr.update(), gr.update())\n",
        "\n",
        "    def process_file(file_obj, consent: bool, anonymize: bool):\n",
        "        if not consent:\n",
        "            return None, {}, \"Consent required\"\n",
        "        if file_obj is None:\n",
        "            return None, {}, \"No image\"\n",
        "        try:\n",
        "            pil = Image.open(file_obj.name).convert(\"RGB\")\n",
        "        except Exception:\n",
        "            return None, {}, \"Invalid image\"\n",
        "        preview = _maybe_blur_preview(pil, anonymize)\n",
        "        probs, pred = _predict_core(pil)  # model on original (not blurred)\n",
        "        return preview, probs, pred\n",
        "\n",
        "    def reprocess_preview(file_obj, consent: bool, anonymize: bool):\n",
        "        # Only re-render preview when toggling anonymize without re-uploading\n",
        "        if not consent or file_obj is None:\n",
        "            return None\n",
        "        try:\n",
        "            pil = Image.open(file_obj.name).convert(\"RGB\")\n",
        "        except Exception:\n",
        "            return None\n",
        "        return _maybe_blur_preview(pil, anonymize)\n",
        "\n",
        "    def clear_all():\n",
        "        return (\n",
        "            None,   # file\n",
        "            None,   # preview\n",
        "            {},     # probs\n",
        "            \"\",     # label\n",
        "        )\n",
        "\n",
        "    with gr.Blocks(title=\"Human Face Emotion Recognition (HFE)\") as demo:\n",
        "        gr.Markdown(\"# Human Face Emotion Recognition (HFE)\")\n",
        "        gr.Markdown(\"Upload an image to classify emotion (consent required).\")\n",
        "\n",
        "        with gr.Accordion(\"Privacy & Consent (read before proceeding)\", open=True):\n",
        "            gr.Markdown(PRIVACY_TEXT)\n",
        "\n",
        "        consent = gr.Checkbox(\n",
        "            label=\"I have read the Privacy Notice and I consent to process the uploaded image in this session.\",\n",
        "            value=False,\n",
        "        )\n",
        "\n",
        "        anonymize = gr.Checkbox(\n",
        "            label=\"Blur preview (anonymize UI only)\",\n",
        "            value=True,\n",
        "        )\n",
        "\n",
        "        file_in = gr.File(\n",
        "            label=\"Upload a face image\",\n",
        "            file_count=\"single\",\n",
        "            file_types=[\"image\"],\n",
        "            visible=False,  # gated by consent\n",
        "        )\n",
        "\n",
        "        preview = gr.Image(label=\"Preview (blurred if enabled)\", interactive=False)\n",
        "        probs_out = gr.Label(num_top_classes=5, label=\"Probabilities\")\n",
        "        pred_out = gr.Textbox(label=\"Predicted Emotion\", interactive=False)\n",
        "        clear_btn = gr.Button(\"Clear & Delete from Session\")\n",
        "\n",
        "        consent.change(\n",
        "            fn=toggle_uploader,\n",
        "            inputs=consent,\n",
        "            outputs=[file_in, preview, probs_out, pred_out],\n",
        "        )\n",
        "\n",
        "        file_in.change(\n",
        "            fn=process_file,\n",
        "            inputs=[file_in, consent, anonymize],\n",
        "            outputs=[preview, probs_out, pred_out],\n",
        "        )\n",
        "\n",
        "        anonymize.change(\n",
        "            fn=reprocess_preview,\n",
        "            inputs=[file_in, consent, anonymize],\n",
        "            outputs=[preview],\n",
        "        )\n",
        "\n",
        "        clear_btn.click(\n",
        "            fn=clear_all,\n",
        "            inputs=None,\n",
        "            outputs=[file_in, preview, probs_out, pred_out],\n",
        "        )\n",
        "\n",
        "    demo.launch(debug=False, server_name=\"0.0.0.0\")\n",
        "\n",
        "\n",
        "# --------------------------- Entry Point ---------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    # 1) Path to your saved model (.keras)\n",
        "    MODEL_PATH = \"/content/hfe_emotion_cnn (2).keras\"  # change if needed\n",
        "\n",
        "    # 2) Must match your training label order EXACTLY\n",
        "    # Example based on your dataset folders (watch spelling: \"Suprise\" vs \"Surprise\")\n",
        "    CLASS_NAMES = [\"Angry\", \"Fear\", \"Happy\", \"Sad\", \"Suprise\"]\n",
        "\n",
        "    # 3) Must match your training input size\n",
        "    IMG_SIZE = 128\n",
        "\n",
        "    # Load model\n",
        "    model = keras.models.load_model(MODEL_PATH)\n",
        "\n",
        "    # Launch UI\n",
        "    launch_gradio(model, CLASS_NAMES, IMG_SIZE)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CF1USYgGFXoI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}